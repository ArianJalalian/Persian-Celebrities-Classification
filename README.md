Ml course final project, instructed by Dr. Malek 
Fall 2023-24 

A simplified Convolutional Neural Network (CNN) architecture was initially explored, aiming to extract meaningful features. However, performance fell short due to signs of overfitting. Modifications, including kernel size adjustments and regularization techniques like L2 regularization and Batch Normalization, were introduced to improve model stability and generalization. Adaptive learning rate management was adopted to refine convergence, leading to the final architecture, which demonstrated improved performance.

Data augmentation was subsequently employed to expand the dataset, enhancing model robustness. The model now achieves satisfactory performance, demonstrating the effectiveness of the adopted techniques. Further improvements and explorations are ongoing to enhance model accuracy and efficiency.
